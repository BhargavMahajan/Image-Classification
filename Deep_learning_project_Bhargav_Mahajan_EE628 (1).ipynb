{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPM2r5dlbXWf",
        "outputId": "e3c40524-7276-4dd1-8d87-b682e7bebac4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "469/469 [==============================] - 160s 337ms/step - loss: 0.2299 - accuracy: 0.9310 - val_loss: 0.0548 - val_accuracy: 0.9825\n",
            "Test loss: 0.05480075255036354\n",
            "Test accuracy: 0.9825000166893005\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.utils import to_categorical\n",
        "#from keras.utils import np_utils\n",
        "\n",
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "\n",
        "# Convert labels to one-hot encoded vectors\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Define the model architecture\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=1, verbose=1, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.utils import to_categorical\n",
        "#from keras.utils import np_utils\n",
        "\n",
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "\n",
        "# Convert labels to one-hot encoded vectors\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Define the model architecture\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='tanh', input_shape=(28, 28, 1)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=1, verbose=1, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGND_E3mtZDo",
        "outputId": "59761166-f68e-4502-9b20-8fa2b3410005"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "469/469 [==============================] - 164s 347ms/step - loss: 0.2250 - accuracy: 0.9327 - val_loss: 0.0577 - val_accuracy: 0.9814\n",
            "Test loss: 0.05767247825860977\n",
            "Test accuracy: 0.9814000129699707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.utils import to_categorical\n",
        "#from keras.utils import np_utils\n",
        "\n",
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "\n",
        "# Convert labels to one-hot encoded vectors\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Define the model architecture\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='tanh', input_shape=(28, 28, 1)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='CategoricalFocalCrossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=1, verbose=1, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kw6n21ZyudvB",
        "outputId": "04eced70-f2d1-446a-b66f-39b8963dbb3a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 337ms/step - accuracy: 0.8581 - loss: 0.0697 - val_accuracy: 0.9811 - val_loss: 0.0062\n",
            "Test loss: 0.0061685629189014435\n",
            "Test accuracy: 0.9811000227928162\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.utils import to_categorical\n",
        "#from keras.utils import np_utils\n",
        "\n",
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "\n",
        "# Convert labels to one-hot encoded vectors\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Define the model architecture\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='CategoricalFocalCrossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=1, verbose=1, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qDVtCDq5tjgH",
        "outputId": "fd8dc5cc-59e6-4cec-9c14-92368596fd0f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 329ms/step - accuracy: 0.8488 - loss: 0.0759 - val_accuracy: 0.9846 - val_loss: 0.0053\n",
            "Test loss: 0.005276480223983526\n",
            "Test accuracy: 0.9846000075340271\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "bq_f8oYIuBZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, BatchNormalization, Activation, Flatten, Dense, Add\n",
        "#from keras.utils import np_utils\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.utils import to_categorical\n",
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Define Residual Block\n",
        "def residual_block(input_layer, filters, kernel_size=(3, 3), strides=(1, 1), padding='same'):\n",
        "    x = Conv2D(filters, kernel_size, strides=strides, padding=padding)(input_layer)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(filters, kernel_size, padding=padding)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Add()([x, input_layer])\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "# Define ResNet Model\n",
        "def resnet_model(input_shape, num_classes):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = Conv2D(32, (3, 3), padding='same')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = residual_block(x, 32)\n",
        "    x = residual_block(x, 32)\n",
        "    x = Conv2D(64, (3, 3), strides=(2, 2), padding='same')(x)\n",
        "    x = residual_block(x, 64)\n",
        "    x = residual_block(x, 64)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=inputs, outputs=x)\n",
        "    return model\n",
        "\n",
        "# Build and compile the model\n",
        "input_shape = (28, 28, 1)\n",
        "num_classes = 10\n",
        "model = resnet_model(input_shape, num_classes)\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=1, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xk_SldcqgXDh",
        "outputId": "e3afda2b-6b08-45e0-ca20-a4ca1b6af50b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n",
            "469/469 [==============================] - 834s 2s/step - loss: 0.1874 - accuracy: 0.9549 - val_loss: 0.0843 - val_accuracy: 0.9743\n",
            "Test loss: 0.08427537232637405\n",
            "Test accuracy: 0.9743000268936157\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Flatten, Dense, Dropout\n",
        "from keras.layers import Conv2D, Reshape\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.utils import to_categorical\n",
        "#from keras.utils import np_utils\n",
        "\n",
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255\n",
        "x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Define the Vision Transformer model\n",
        "def vision_transformer(input_shape, num_classes):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = Conv2D(64, kernel_size=3, strides=2, padding='same', activation='relu')(inputs)\n",
        "    x = Conv2D(128, kernel_size=3, strides=2, padding='same', activation='relu')(x)\n",
        "    x = Conv2D(256, kernel_size=3, strides=2, padding='same', activation='relu')(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(512, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(num_classes, activation='softmax')(x)\n",
        "    model = Model(inputs=inputs, outputs=x)\n",
        "    return model\n",
        "\n",
        "# Build the model\n",
        "input_shape = (28, 28, 1)\n",
        "num_classes = 10\n",
        "model = vision_transformer(input_shape, num_classes)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=1, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y77AcUJqwnin",
        "outputId": "fc7df0ec-2c41-47dc-9198-0c5f865d3750"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "469/469 [==============================] - 132s 277ms/step - loss: 0.1949 - accuracy: 0.9394 - val_loss: 0.0463 - val_accuracy: 0.9835\n",
            "Test loss: 0.04630938544869423\n",
            "Test accuracy: 0.9835000038146973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy keras scikit-learn\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opFQrJW7bre6",
        "outputId": "82dc87f2-bb33-47b0-ef27-04d285261e88"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikeras\n",
        "\n",
        "from scikeras.wrappers import KerasClassifier"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QG-q6vqFddpF",
        "outputId": "2963d233-2067-4734-f93f-5ee84aede162"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikeras in /usr/local/lib/python3.10/dist-packages (0.13.0)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from scikeras) (3.3.3)\n",
            "Requirement already satisfied: scikit-learn>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from scikeras) (1.4.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (1.25.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (13.7.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (3.9.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.11.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->scikeras) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.4.2->scikeras) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras>=3.2.0->scikeras) (4.11.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->scikeras) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.utils import to_categorical\n",
        "#from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "#from keras.utils import np_utils\n",
        "from sklearn.metrics import accuracy_score\n",
        "#from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.utils import to_categorical"
      ],
      "metadata": {
        "id": "_KHLzJY2edds"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32') / 255\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)\n",
        "\n",
        "# Define base model (CNN)\n",
        "def create_base_model():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(32, (5, 5), input_shape=(28, 28, 1), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Define the RMDL model\n",
        "def create_rmdl_model():\n",
        "    models = []\n",
        "    for _ in range(3):  # Create 3 base models\n",
        "        model = KerasClassifier(build_fn=create_base_model, epochs=1, batch_size=200, verbose=0)\n",
        "        models.append(model)\n",
        "    rmdl_model = RandomForestClassifier(n_estimators=3)\n",
        "    return models, rmdl_model\n",
        "\n",
        "# Train the base models\n",
        "base_models, rmdl_model = create_rmdl_model()\n",
        "for model in base_models:\n",
        "    model.fit(x_train, y_train)\n",
        "\n",
        "# Prepare predictions from base models for input to the Random Forest\n",
        "predictions = []\n",
        "for model in base_models:\n",
        "    predictions.append(model.predict_proba(x_train))\n",
        "\n",
        "# Concatenate the predictions from base models as features\n",
        "train_features = np.concatenate(predictions, axis=1)\n",
        "\n",
        "# Train the Random Forest\n",
        "rmdl_model.fit(train_features, np.argmax(y_train, axis=1))\n",
        "\n",
        "# Prepare test features\n",
        "test_predictions = []\n",
        "for model in base_models:\n",
        "    test_predictions.append(model.predict_proba(x_test))\n",
        "test_features = np.concatenate(test_predictions, axis=1)\n",
        "\n",
        "# Predict using the Random Forest model\n",
        "y_pred = rmdl_model.predict(test_features)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(np.argmax(y_test, axis=1), y_pred)\n",
        "print('Accuracy:', accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUqHlF8fbs12",
        "outputId": "9fac1d20-715b-46fb-9049-98d68ca1b65c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "/usr/local/lib/python3.10/dist-packages/scikeras/wrappers.py:925: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
            "  X, y = self._initialize(X, y)\n",
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.975\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, concatenate, Flatten, Dense\n",
        "#from keras.utils import np_utils\n",
        "\n",
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data\n",
        "x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255\n",
        "x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Define the Inception model\n",
        "def inception_model(input_shape):\n",
        "    input_layer = Input(shape=input_shape)\n",
        "\n",
        "    tower_1 = Conv2D(64, (1,1), padding='same', activation='relu')(input_layer)\n",
        "    tower_1 = Conv2D(64, (3,3), padding='same', activation='relu')(tower_1)\n",
        "\n",
        "    tower_2 = Conv2D(64, (1,1), padding='same', activation='relu')(input_layer)\n",
        "    tower_2 = Conv2D(64, (5,5), padding='same', activation='relu')(tower_2)\n",
        "\n",
        "    tower_3 = MaxPooling2D((3,3), strides=(1,1), padding='same')(input_layer)\n",
        "    tower_3 = Conv2D(64, (1,1), padding='same', activation='relu')(tower_3)\n",
        "\n",
        "    output = concatenate([tower_1, tower_2, tower_3], axis=3)\n",
        "\n",
        "    output = Flatten()(output)\n",
        "    output = Dense(128, activation='relu')(output)\n",
        "    output = Dense(10, activation='softmax')(output)\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output)\n",
        "    return model\n",
        "\n",
        "# Build the model\n",
        "input_shape = (28, 28, 1)\n",
        "model = inception_model(input_shape)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, batch_size=128, epochs=1, validation_data=(x_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhWU9qCUfJRZ",
        "outputId": "2722ebd7-4877-4fd9-d023-b1ad65abb514"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1568s\u001b[0m 3s/step - accuracy: 0.9022 - loss: 0.3161 - val_accuracy: 0.9824 - val_loss: 0.0518\n",
            "Test loss: 0.051784489303827286\n",
            "Test accuracy: 0.9824000000953674\n"
          ]
        }
      ]
    }
  ]
}